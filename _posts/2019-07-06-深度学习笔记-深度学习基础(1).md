---
layout: post
title: 深度学习笔记-深度学习基础(1)
category: DeepLearning
tags: [DeepLearning]
excerpt_separator: <!-- more -->
excerpt: 主要内容包括神经网络介绍、数据表示、张量的操作、常见的向量数据、张量运算。
typora-copy-images-to: ..\assets\images
---

深度学习笔记-深度学习基础(1)
# 神经网络的数学基础

***

## 初识神经网络

主要内容包括神经网络介绍、数据表示、张量的操作、常见的向量数据、张量运算。

<!-- more -->

神经网络的核心组件是**层**，大多数深度学习都是将简单的层链接起来，从而实现渐进式的数据蒸馏。深度学习模型就像是数据处理的筛子，包含一系列越来越精细的数据过滤器（即层）。

模型编译时，需要三个参数：

- **损失函数（loss function）**：网络如何衡量在训练数据上的性能
- **优化器（optimizer）**：基于训练数据和损失函数来更新网络的机制
- **在训练和测试过程中需要监控的指标（metric）**：如精度、loss
***

***

## 神经网络的数据表示

数据存储在多维Numpy数组中，也叫**张量(tensor)**，它是一个数据容器，是矩阵向任意维度的推广，张量的维度通常叫做**轴（axis）**。

### 标量（0D张量）

顾名思义，仅包含一个数字

### 向量（1D张量）

数字组成的数组叫一维张量，仅有一个轴。有5个元素的向量被称为5D向量，但仍然叫做1D张量。

### 矩阵（2D张量）

### 高维张量（n D张量）

### 张量的关键属性

- 轴的个数（阶）ndim

- 形状 是一个整数元组，向量的形状只包含一个元素，如（5，）；标量的形状为控，即（） shape

- 数据类型 dtype

  ## 常见张量数据

  - **向量数据**  2D张量，（样本轴，特征轴）。
  - **时间序列或序列数据**  3D张量，（样本轴，时间轴，特征轴）。如股票价格、推文数据
  - **图像数据**  4D张量 （样本轴，高度，宽度，颜色深度）（有通道在前和在后之分）
  - **视频数据 ** 5D张量 （样本轴，帧，高度，宽度，颜色深度）

***

## 张量基本操作

### 张量切片

同list切片

## 张量运算

- **+、-**  逐元素相加、减

- **np.dot（x，y）** 点积

- **relu（x）** max（x，0）

- **广播**  较小的张量通过广播，使得ndim与较大的张量相同。重复的操作是完全虚拟的，只出现在算法中，没有出现在内存中。

- **张量变形** np.reshape（）

## 随机梯度下降及其变体

**随机**  是指每批数据都是随机抽取的

**SGD ** 小批量SGD  每次取一批数据；真SGD  每次只抽取一个样本；批量SGD 每次迭代所有数据（每次更新都更加精确，但是计算代价也会很高）

**优化器** 计算下一次权重更新时，考虑上一次权重更新。如带动量的SGD、Adagrad、RMSProp。动量解决了SGD的两个问题：**收敛速度**和**局部极小点**。动量的方法实现过程类似于移动小球，不仅要考虑当前的加速度，还要考虑之前的累加的速度。

## 深度学习几何解释

**仿射变换**、**旋转**、**缩放**等基本的几何操作等都可以理解为张量运算。神经网络可以解释为在高维空间中非常复杂的几何变换。

例子：想象有两张彩纸：一张红色，一张蓝色。将两张纸叠在一起揉成小球。这个皱巴巴的纸球就是输入的数据，每张纸对应于分类问题的一个类别（三维空间中无法准确分开）。神经网络要做的就是找到可以让纸秋恢复平整的变换，从而能够再次让两个类别明确可分。（变换为高维空间上的两张纸）

让纸球恢复平整就是机器学习的内容：**为复杂的、高度折叠的数据流形找到简洁的表示**。